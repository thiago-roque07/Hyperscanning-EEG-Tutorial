{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d40b9bd6",
   "metadata": {},
   "source": [
    "# Script 2: Extracting the Audio and Decimating the Data\n",
    "\n",
    "**Python Code to Accompany Douglas, Tremblay, and Newman, \"A two for one special: EEG hyperscanning using an existing single-person EEG recording setup\"**\n",
    "\n",
    "---\n",
    "Copyright (c) 2021 Aaron J Newman & Caitriona L Douglas, NeuroCognitive Imaging Lab, Dalhousie University\n",
    "\n",
    "This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License along with this program; if not, write to the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e872f153-bd92-47d4-9424-646ad8ac2965",
   "metadata": {},
   "source": [
    "# Read in raw data, delete audio channel, and save decimated version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea1608ce-daac-4b16-b2ea-22b35679612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "import mne\n",
    "mne.set_log_level(verbose='error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f48c99-fe69-40a0-ab19-580141165f1c",
   "metadata": {},
   "source": [
    "### Set Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a1d7aa5-36a2-4b70-b775-d76d3eead87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Subject\" is the name of your input file, without the extensions\n",
    "subject = 'conversation_eeg_sample'\n",
    "\n",
    "# Input should be continuous EEG data \n",
    "raw_fname = subject + '.vhdr'\n",
    "\n",
    "# Filter cutoffs and other parameters\n",
    "l_freq_use = 0.1\n",
    "l_freq_ICA = 1.0\n",
    "h_freq = 20.0\n",
    "\n",
    "# specify the time window for epoching\n",
    "tmin = -0.2  # start of each epoch (in sec)\n",
    "tmax =  1.0  # end of each epoch (in sec)\n",
    "\n",
    "# maximum number of ICs to reject in ICA artifact correction\n",
    "ica_random_state = 42  # seed so ICA is reproducable each time it's run\n",
    "# Specify n_components as a decimal to set % explained variance\n",
    "n_components = .99\n",
    "\n",
    "baseline = (None, 0)  # means from the first instant to t = 0\n",
    "reject = dict(eeg=200e-6, eog=200e-6)  # EEG data are in V, so e-6 gives microVolts\n",
    "\n",
    "# standard montage file to look up channel locations\n",
    "montage_fname = 'standard_1005'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34498bae-b66b-4d59-88e4-ba545ea8c070",
   "metadata": {},
   "source": [
    "## Import raw data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24a35866-679a-4586-82e5-78216445ebb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\thiag\\\\OneDrive - Georgia Institute of Technology\\\\Gatech PhD\\\\My PhD\\\\Two for one\\\\conversation_eeg_sample.vhdr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12636/4204907066.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m raw = mne.io.read_raw_brainvision(raw_fname,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                   \u001b[0meog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'P1_Canthi'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P2_Canthi'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                   misc=('P1_RN','P1_LMass','P1_LN','P1_RMass',\n\u001b[0;32m      4\u001b[0m                                         \u001b[1;34m'P2_RN'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P2_LMass'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P2_LN'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'P2_RMass'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                         'Audio'), \n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mne\\io\\brainvision\\brainvision.py\u001b[0m in \u001b[0;36mread_raw_brainvision\u001b[1;34m(vhdr_fname, eog, misc, scale, preload, verbose)\u001b[0m\n\u001b[0;32m    855\u001b[0m     \u001b[0mmne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRaw\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mDocumentation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mattribute\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmethods\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m     \"\"\"\n\u001b[1;32m--> 857\u001b[1;33m     return RawBrainVision(vhdr_fname=vhdr_fname, eog=eog,\n\u001b[0m\u001b[0;32m    858\u001b[0m                           \u001b[0mmisc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m                           verbose=verbose)\n",
      "\u001b[1;32m<decorator-gen-211>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, vhdr_fname, eog, misc, scale, preload, verbose)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mne\\io\\brainvision\\brainvision.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, vhdr_fname, eog, misc, scale, preload, verbose)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mvhdr_fname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvhdr_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         (info, data_fname, fmt, order, n_samples, mrk_fname, montage,\n\u001b[1;32m---> 73\u001b[1;33m          orig_units) = _get_vhdr_info(vhdr_fname, eog, misc, scale)\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_fname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mne\\io\\brainvision\\brainvision.py\u001b[0m in \u001b[0;36m_get_vhdr_info\u001b[1;34m(vhdr_fname, eog, misc, scale)\u001b[0m\n\u001b[0;32m    455\u001b[0m                       \"not a file with extension '%s'.\" % ext)\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0msettings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcinfostr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_aux_vhdr_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvhdr_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unlocked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mne\\io\\brainvision\\brainvision.py\u001b[0m in \u001b[0;36m_aux_vhdr_info\u001b[1;34m(vhdr_fname)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_aux_vhdr_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvhdr_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[1;34m\"\"\"Aux function for _get_vhdr_info.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvhdr_fname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m         \u001b[1;31m# extract the first section to resemble a cfg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\thiag\\\\OneDrive - Georgia Institute of Technology\\\\Gatech PhD\\\\My PhD\\\\Two for one\\\\conversation_eeg_sample.vhdr'"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw_brainvision(raw_fname,\n",
    "                                  eog=('P1_Canthi','P2_Canthi'),\n",
    "                                  misc=('P1_RN','P1_LMass','P1_LN','P1_RMass',\n",
    "                                        'P2_RN','P2_LMass','P2_LN','P2_RMass',\n",
    "                                        'Audio'), \n",
    "                                  preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5004f-8b73-4bf2-8264-e148140940cc",
   "metadata": {},
   "source": [
    "## Export audio track to .wav file\n",
    "This step will result in the output of a file containing the audio track that was recorded into the EEG data. This is stared in a WAV file with the same name as the input data file. This WAV file is used to transcribe the conversation and find word onsent timings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e60134a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract audio track into separate data structure\n",
    "Audio = raw.get_data(picks=raw.ch_names.index('Audio'))\n",
    "# re-format audio for export (16 bit int; time x channels rather than channels x time)\n",
    "audout = np.int16(Audio/np.max(np.abs(Audio)) * 32767).T\n",
    "\n",
    "audio_fname= subject + '.wav'\n",
    "\n",
    "# export using scipy's io\n",
    "from scipy.io import wavfile\n",
    "wavfile.write(audio_fname, np.int16(raw.info['sfreq']), audout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94316670-c713-494d-8b56-661229b48102",
   "metadata": {},
   "source": [
    "## Decimate EEG to 500 Hz\n",
    "This make the file mauch smaller and easier to work with than the original 10,000 Hz sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0565039b-a708-4fdc-91e8-2a32cec4264d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        <td>March 03, 2017  12:02:56 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 56 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>P1_Canthi, P2_Canthi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>500.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "\n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>conversation_eeg_sample.eeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:10:15 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<RawBrainVision | conversation_eeg_sample.eeg, 66 x 307550 (615.1 s), ~154.9 MB, data loaded>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_decim = raw.copy().resample(500, npad='auto')\n",
    "raw_decim.drop_channels('Audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19c0be75-5934-4c6c-9932-f80f62263026",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_decim.save(subject + '_decim-raw.fif', overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
